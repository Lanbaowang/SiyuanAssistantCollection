/* esm.sh - esbuild bundle(@huggingface/hub@0.12.2) es2022 production */
var Ae=Object.defineProperty,Pe=(e,t,n)=>t in e?Ae(e,t,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[t]=n,E=(e,t,n)=>(Pe(e,typeof t!="symbol"?t+"":t,n),n);function oe(e){if(globalThis.Buffer)return globalThis.Buffer.from(e).toString("base64");{let t=[];return e.forEach(n=>{t.push(String.fromCharCode(n))}),globalThis.btoa(t.join(""))}}var Re=typeof window<"u"&&typeof window.document<"u",Se=typeof self=="object"&&self.constructor&&self.constructor.name==="DedicatedWorkerGlobalScope",Ie=!Re&&!Se,X=!Ie,b="https://huggingface.co";async function g(e,t){var n,o;let r=new ve(e.url,e.status,(n=e.headers.get("X-Request-Id"))!=null?n:t?.requestId);if(r.message=`Api error with status ${r.statusCode}.${t?.message?` ${t.message}.`:""} Request ID: ${r.requestId}, url: ${r.url}`,(o=e.headers.get("Content-Type"))!=null&&o.startsWith("application/json")){let i=await e.json();r.message=i.error||i.message||r.message,r.data=i}else r.data={message:await e.text()};throw r}var ve=class extends Error{constructor(e,t,n,o){super(o),E(this,"statusCode"),E(this,"url"),E(this,"requestId"),E(this,"data"),this.statusCode=t,this.requestId=n,this.url=e}},q=class extends Error{};function y(e){if(!(!e||e.accessToken===void 0||e.accessToken===null)&&!e.accessToken.startsWith("hf_"))throw new TypeError("Your access token must start with 'hf_'")}function Oe(e,t){return t?Array(t-e).fill(0).map((n,o)=>e+o):Array(e).fill(0).map((n,o)=>o)}function ce(e,t){if(isNaN(t)||t<1)throw new RangeError("Invalid chunk size: "+t);return e.length?e.length<=t?[e]:Oe(Math.ceil(e.length/t)).map(n=>e.slice(n*t,(n+1)*t)):[]}async function be(e,t){let n=[],o=new Set,r=0;for(let i of e){let s=r++,l=i().then(a=>{n[s]=a,o.delete(l)});o.add(l),o.size>=t&&await Promise.race(o)}return await Promise.all(o),n}async function de(e,t){let n=[];for await(let o of e){let r=o().then(()=>{n.splice(n.indexOf(r),1)});n.push(r),n.length>=t&&await Promise.race(n)}await Promise.all(n)}async function*H(e){let t=[];function n(){let r,i,s=new Promise((l,a)=>{r=l,i=a});t.push({p:s,resolve:r,reject:i})}n();let o=Promise.resolve().then(()=>e(r=>{var i;n(),(i=t.at(-2))==null||i.resolve({done:!1,value:r})},r=>{var i;n(),(i=t.at(-2))==null||i.resolve({done:!0,value:r})},r=>{var i;return(i=t.shift())==null?void 0:i.reject(r)})).catch(r=>{var i;return(i=t.shift())==null?void 0:i.reject(r)});for(;;){let r=t[0];if(!r)throw new Error("Logic error in eventGenerator, promises should never be empty");let i=await r.p;if(t.shift(),i.done)return await o,i.value;yield i.value}throw new Error("Unreachable")}function xe(e){if(globalThis.Buffer)return globalThis.Buffer.from(e).toString("hex");{let t=[];return e.forEach(n=>{t.push(n.toString(16).padStart(2,"0"))}),t.join("")}}var ue=`
// Would prefer no CDN, but need a clever way to not burden the main file of the bundle
importScripts("https://cdn.jsdelivr.net/npm/hash-wasm@4/dist/sha256.umd.min.js");

const createSHA256 = hashwasm.createSHA256;

self.addEventListener('message', async (event) => {
	const { file } = event.data;
	const sha256 = await createSHA256();
	sha256.init();
	const reader = file.stream().getReader();
	const total = file.size;
	let bytesDone = 0;
	while (true) {
		const { done, value } = await reader.read();
		if (done) {
			break;
		}
		sha256.update(value);
		bytesDone += value.length;
		postMessage({ progress: bytesDone / total });
	}
	postMessage({ sha256: sha256.digest('hex') });
});
`,ye=[],L=new Set,j,re=new Promise(e=>{j=e});async function Le(e){{let n=ye.pop();if(n)return L.add(n),n}if(!e){let n=new Worker(URL.createObjectURL(new Blob([ue])));return L.add(n),n}if(e<=0)throw new TypeError("Invalid webworker pool size: "+e);for(;L.size>=e;)await re;let t=new Worker(URL.createObjectURL(new Blob([ue])));return L.add(t),t}async function We(e,t){if(!t)return M(e);L.delete(e),ye.push(e);let n=j;re=new Promise(o=>{j=o}),n()}function M(e){L.delete(e),e.terminate();let t=j;re=new Promise(n=>{j=n}),t()}async function*Be(e,t){var n,o;yield 0;let r=typeof t?.useWebWorker=="object"&&t?.useWebWorker.minSize!==void 0?t.useWebWorker.minSize:1e7;if(e.size<r&&((n=globalThis.crypto)!=null&&n.subtle)){let i=xe(new Uint8Array(await globalThis.crypto.subtle.digest("SHA-256",e instanceof Blob?await e.arrayBuffer():e)));return yield 1,i}if(X){if(t?.useWebWorker)try{let c=typeof t?.useWebWorker=="object"?t.useWebWorker.poolSize:void 0,d=await Le(c);return yield*H((u,U,O)=>{d.addEventListener("message",h=>{var p;if(h.data.sha256)We(d,c),U(h.data.sha256);else if(h.data.progress){u(h.data.progress);try{(p=t.abortSignal)==null||p.throwIfAborted()}catch(A){M(d),O(A)}}else M(d),O(h)}),d.addEventListener("error",h=>{M(d),O(h.error)}),d.postMessage({file:e})})}catch(c){console.warn("Failed to use web worker for sha256",c)}te||(te=await import("/v135/hash-wasm@4.11.0/es2022/hash-wasm.mjs"));let i=await te.createSHA256();i.init();let s=e.stream().getReader(),l=e.size,a=0;for(;;){let{done:c,value:d}=await s.read();if(c)break;i.update(d),a+=d.length,yield a/l,(o=t?.abortSignal)==null||o.throwIfAborted()}return i.digest("hex")}return ee||(ee=await import("/v135/@huggingface/hub@0.12.2/es2022/dist/browser/sha256-node-TNZ2WHTI.js")),yield*ee.sha256Node(e,{abortSignal:t?.abortSignal})}var ee,te;function S(e){if(typeof e!="string")return e;if(e.startsWith("model/")||e.startsWith("models/"))throw new TypeError("A repo designation for a model should not start with 'models/', directly specify the model namespace / name");if(e.startsWith("space/"))throw new TypeError("Spaces should start with 'spaces/', plural, not 'space/'");if(e.startsWith("dataset/"))throw new TypeError("Datasets should start with 'dataset/', plural, not 'dataset/'");let t=e.split("/").length-1;if(e.startsWith("spaces/")){if(t!==2)throw new TypeError("Space Id must include namespace and name of the space");return{type:"space",name:e.slice(7)}}if(e.startsWith("datasets/")){if(t>2)throw new TypeError("Too many slashes in repo designation: "+e);return{type:"dataset",name:e.slice(9)}}if(t>1)throw new TypeError("Too many slashes in repo designation: "+e);return{type:"model",name:e}}var F=class extends Blob{constructor(e,t,n,o,r,i){super([]),E(this,"url"),E(this,"start"),E(this,"end"),E(this,"contentType"),E(this,"full"),E(this,"fetch"),this.url=e,this.start=t,this.end=n,this.contentType=o,this.full=r,this.fetch=i}static async create(e,t){var n,o;let r=(n=t?.fetch)!=null?n:fetch,i=await r(e,{method:"HEAD"}),s=Number(i.headers.get("content-length")),l=i.headers.get("content-type")||"";return!(i.headers.get("accept-ranges")==="bytes")||s<((o=t?.cacheBelow)!=null?o:1e6)?await(await r(e)).blob():new F(e,0,s,l,!0,r)}get size(){return this.end-this.start}get type(){return this.contentType}slice(e=0,t=this.size){return(e<0||t<0)&&new TypeError("Unsupported negative start/end on FileBlob.slice"),new F(this.url,this.start+e,Math.min(this.start+t,this.end),this.contentType,e===0&&t===this.size?this.full:!1,this.fetch)}async arrayBuffer(){return(await this.fetchRange()).arrayBuffer()}async text(){return(await this.fetchRange()).text()}stream(){let e=new TransformStream;return this.fetchRange().then(t=>{var n;return(n=t.body)==null?void 0:n.pipeThrough(e)}).catch(t=>e.writable.abort(t.message)),e.readable}fetchRange(){let e=this.fetch;return this.full?e(this.url):e(this.url,{headers:{Range:`bytes=${this.start}-${this.end-1}`}})}};async function Ce(e,t){if(e.protocol==="http:"||e.protocol==="https:")return F.create(e,{fetch:t?.fetch});if(X)throw new TypeError(`Unsupported URL protocol "${e.protocol}"`);if(e.protocol==="file:"){let{FileBlob:n}=await import("/v135/@huggingface/hub@0.12.2/es2022/dist/browser/FileBlob-7MRLQ6TG.js");return n.create(e)}throw new TypeError(`Unsupported URL protocol "${e.protocol}"`)}var je=5,Fe=5,De=5;function C(e){let t=e.operation==="addOrUpdate";if(t&&!(e.content instanceof Blob))throw new TypeError("Precondition failed: op.content should be a Blob");return t}async function*me(e){var t,n,o,r,i,s,l;y(e.credentials);let a=S(e.repo);yield{event:"phase",phase:"preuploading"};let c=new Map,d=new AbortController,u=d.signal;u.throwIfAborted||(u.throwIfAborted=()=>{if(u.aborted)throw new DOMException("Aborted","AbortError")}),e.abortSignal&&e.abortSignal.addEventListener("abort",()=>d.abort());try{let U=await Promise.all(e.operations.map(async h=>{if(h.operation!=="addOrUpdate")return h;if(!(h.content instanceof URL))return{...h,content:h.content};let p=await Ce(h.content,{fetch:e.fetch});return u?.throwIfAborted(),{...h,content:p}})),O=(t=U.filter(C).find(h=>h.path===".gitattributes"))==null?void 0:t.content;for(let h of ce(U.filter(C),100)){let p={gitAttributes:O&&await O.text(),files:await Promise.all(h.map(async m=>({path:m.path,size:m.content.size,sample:oe(new Uint8Array(await m.content.slice(0,512).arrayBuffer()))})))};u?.throwIfAborted();let A=await((n=e.fetch)!=null?n:fetch)(`${(o=e.hubUrl)!=null?o:b}/api/${a.type}s/${a.name}/preupload/${encodeURIComponent((r=e.branch)!=null?r:"main")}`+(e.isPullRequest?"?create_pr=1":""),{method:"POST",headers:{...e.credentials&&{Authorization:`Bearer ${e.credentials.accessToken}`},"Content-Type":"application/json"},body:JSON.stringify(p),signal:u});if(!A.ok)throw await g(A);let k=await A.json();for(let m of k.files)m.uploadMode==="lfs"&&c.set(m.path,null)}yield{event:"phase",phase:"uploadingLargeFiles"};for(let h of ce(U.filter(C).filter(p=>c.has(p.path)),100)){let p=yield*H((f,I,K)=>be(h.map(w=>async()=>{let D=Be(w.content,{useWebWorker:e.useWebWorkers,abortSignal:u}),P;do P=await D.next(),P.done||f({event:"fileProgress",path:w.path,progress:P.value,state:"hashing"});while(!P.done);let z=P.value;return c.set(w.path,P.value),z}),je).then(I,K));u?.throwIfAborted();let A={operation:"upload",transfers:["basic","multipart"],hash_algo:"sha_256",...!e.isPullRequest&&{ref:{name:(i=e.branch)!=null?i:"main"}},objects:h.map((f,I)=>({oid:p[I],size:f.content.size}))},k=await((s=e.fetch)!=null?s:fetch)(`${(l=e.hubUrl)!=null?l:b}/${a.type==="model"?"":a.type+"s/"}${a.name}.git/info/lfs/objects/batch`,{method:"POST",headers:{...e.credentials&&{Authorization:`Bearer ${e.credentials.accessToken}`},Accept:"application/vnd.git-lfs+json","Content-Type":"application/vnd.git-lfs+json"},body:JSON.stringify(A),signal:u});if(!k.ok)throw await g(k);let m=await k.json(),_=k.headers.get("X-Request-Id")||void 0,v=new Map(h.map((f,I)=>[p[I],f]));yield*H((f,I,K)=>de(m.objects.map(w=>async()=>{var D,P,z;let $=v.get(w.oid);if(!$)throw new q("Unrequested object ID in response");if(u?.throwIfAborted(),w.error){let R=`Error while doing LFS batch call for ${h[p.indexOf(w.oid)].path}: ${w.error.message}${_?` - Request ID: ${_}`:""}`;throw new ve(k.url,w.error.code,_,R)}if(!((D=w.actions)!=null&&D.upload)){f({event:"fileProgress",path:$.path,progress:1,state:"uploading"});return}f({event:"fileProgress",path:$.path,progress:0,state:"uploading"});let W=$.content,B=w.actions.upload.header;if(B?.chunk_size){let R=parseInt(B.chunk_size),Y=w.actions.upload.href,N=Object.keys(B).filter(T=>/^[0-9]+$/.test(T));if(N.length!==Math.ceil(W.size/R))throw new Error("Invalid server response to upload large LFS file, wrong number of parts");let ie={oid:w.oid,parts:N.map(T=>({partNumber:+T,etag:""}))},Ue=T=>f({event:"fileProgress",path:$.path,progress:T,state:"uploading"});await de(N.map(T=>async()=>{var ae;u?.throwIfAborted();let Q=parseInt(T)-1,V=W.slice(Q*R,(Q+1)*R),Z=await((ae=e.fetch)!=null?ae:fetch)(B[T],{method:"PUT",body:V instanceof F&&X?await V.arrayBuffer():V,signal:u,progressHint:{path:$.path,part:Q,numParts:N.length,progressCallback:Ue}});if(!Z.ok)throw await g(Z,{requestId:_,message:`Error while uploading part ${T} of ${h[p.indexOf(w.oid)].path} to LFS storage`});let le=Z.headers.get("ETag");if(!le)throw new Error("Cannot get ETag of part during multipart upload");ie.parts[Number(T)-1].etag=le}),De),u?.throwIfAborted();let se=await((P=e.fetch)!=null?P:fetch)(Y,{method:"POST",body:JSON.stringify(ie),headers:{Accept:"application/vnd.git-lfs+json","Content-Type":"application/vnd.git-lfs+json"},signal:u});if(!se.ok)throw await g(se,{requestId:_,message:`Error completing multipart upload of ${h[p.indexOf(w.oid)].path} to LFS storage`});f({event:"fileProgress",path:$.path,progress:1,state:"uploading"})}else{let R=await((z=e.fetch)!=null?z:fetch)(w.actions.upload.href,{method:"PUT",headers:{..._?{"X-Request-Id":_}:void 0},body:W instanceof F&&X?await W.arrayBuffer():W,signal:u,progressHint:{path:$.path,progressCallback:Y=>f({event:"fileProgress",path:$.path,progress:Y,state:"uploading"})}});if(!R.ok)throw await g(R,{requestId:_,message:`Error while uploading ${h[p.indexOf(w.oid)].path} to LFS storage`});f({event:"fileProgress",path:$.path,progress:1,state:"uploading"})}}),Fe).then(I,K))}return u?.throwIfAborted(),yield{event:"phase",phase:"committing"},yield*H(async(h,p,A)=>{var k,m,_;return((k=e.fetch)!=null?k:fetch)(`${(m=e.hubUrl)!=null?m:b}/api/${a.type}s/${a.name}/commit/${encodeURIComponent((_=e.branch)!=null?_:"main")}`+(e.isPullRequest?"?create_pr=1":""),{method:"POST",headers:{...e.credentials&&{Authorization:`Bearer ${e.credentials.accessToken}`},"Content-Type":"application/x-ndjson"},body:[{key:"header",value:{summary:e.title,description:e.description,parentCommit:e.parentCommit}},...await Promise.all(U.map(v=>{if(C(v)){let f=c.get(v.path);if(f)return{key:"lfsFile",value:{path:v.path,algo:"sha256",size:v.content.size,oid:f}}}return ze(v)}))].map(v=>JSON.stringify(v)).join(`
`),signal:u,progressHint:{progressCallback:v=>{for(let f of U)C(f)&&!c.has(f.path)&&h({event:"fileProgress",path:f.path,progress:v,state:"uploading"})}}}).then(async v=>{if(!v.ok)throw await g(v);let f=await v.json();p({pullRequestUrl:f.pullRequestUrl,commit:{oid:f.commitOid,url:f.commitUrl},hookOutput:f.hookOutput})}).catch(A)})}catch(U){throw d.abort(),U}}async function J(e){let t=me(e),n=await t.next();for(;!n.done;)n=await t.next();return n.value}async function ze(e){switch(e.operation){case"addOrUpdate":return{key:"file",value:{content:oe(new Uint8Array(await e.content.arrayBuffer())),path:e.path,encoding:"base64"}};case"delete":return{key:"deletedFile",value:{path:e.path}};default:throw new TypeError("Unknown operation: "+e.operation)}}async function Ke(e){var t,n;y(e.credentials);let o=S(e.repo),[r,i]=o.name.split("/");if(!r||!i)throw new TypeError(`"${o.name}" is not a fully qualified repo name. It should be of the form "{namespace}/{repoName}".`);let s=await((t=e.fetch)!=null?t:fetch)(`${(n=e.hubUrl)!=null?n:b}/api/repos/create`,{method:"POST",body:JSON.stringify({name:i,private:e.private,organization:r,license:e.license,...o.type==="space"?{type:"space",sdk:"static"}:{type:o.type},files:e.files?await Promise.all(e.files.map(async a=>({encoding:"base64",path:a.path,content:oe(new Uint8Array(a.content instanceof Blob?await a.content.arrayBuffer():a.content))}))):void 0}),headers:{Authorization:`Bearer ${e.credentials.accessToken}`,"Content-Type":"application/json"}});if(!s.ok)throw await g(s);return{repoUrl:(await s.json()).url}}function Ye(e){var t;return J({credentials:e.credentials,repo:e.repo,operations:[{operation:"delete",path:e.path}],title:(t=e.commitTitle)!=null?t:`Delete ${e.path}`,description:e.commitDescription,hubUrl:e.hubUrl,branch:e.branch,isPullRequest:e.isPullRequest,parentCommit:e.parentCommit,fetch:e.fetch})}function Qe(e){var t;return J({credentials:e.credentials,repo:e.repo,operations:e.paths.map(n=>({operation:"delete",path:n})),title:(t=e.commitTitle)!=null?t:`Deletes ${e.paths.length} files`,description:e.commitDescription,hubUrl:e.hubUrl,branch:e.branch,isPullRequest:e.isPullRequest,parentCommit:e.parentCommit,fetch:e.fetch})}async function Ve(e){var t,n;y(e.credentials);let o=S(e.repo),[r,i]=o.name.split("/"),s=await((t=e.fetch)!=null?t:fetch)(`${(n=e.hubUrl)!=null?n:b}/api/repos/delete`,{method:"DELETE",body:JSON.stringify({name:i,organization:r,type:o.type}),headers:{Authorization:`Bearer ${e.credentials.accessToken}`,"Content-Type":"application/json"}});if(!s.ok)throw await g(s)}async function ne(e){var t,n,o;y(e.credentials);let r=S(e.repo),i=`${(t=e.hubUrl)!=null?t:b}/${r.type==="model"?"":`${r.type}s/`}${r.name}/${e.raw?"raw":"resolve"}/${encodeURIComponent((n=e.revision)!=null?n:"main")}/${e.path}`,s=await((o=e.fetch)!=null?o:fetch)(i,{headers:{...e.credentials?{Authorization:`Bearer ${e.credentials.accessToken}`}:{},...e.range?{Range:`bytes=${e.range[0]}-${e.range[1]}`}:{}}});if(s.status===404&&s.headers.get("X-Error-Code")==="EntryNotFound")return null;if(!s.ok)throw await g(s);return s}async function Ze(e){var t,n,o;y(e.credentials);let r=S(e.repo),i=(t=e.hubUrl)!=null?t:b,s=`${i}/${r.type==="model"?"":`${r.type}s/`}${r.name}/${e.raw?"raw":"resolve"}/${encodeURIComponent((n=e.revision)!=null?n:"main")}/${e.path}`+(e.noContentDisposition?"?noContentDisposition=1":""),l=await((o=e.fetch)!=null?o:fetch)(s,{method:"GET",headers:e.credentials?{Authorization:`Bearer ${e.credentials.accessToken}`,Range:"bytes=0-0"}:{}});if(l.status===404&&l.headers.get("X-Error-Code")==="EntryNotFound")return null;if(!l.ok)throw await g(l);let a=l.headers.get("ETag");if(!a)throw new q("Expected ETag");let c=l.headers.get("Content-Length");if(!c)throw new q("Expected size information");let d=parseInt(c);if(isNaN(d))throw new q("Invalid file size received");return{etag:a,size:d,downloadLink:new URL(l.url).hostname!==new URL(i).hostname?l.url:null}}async function he(e){var t,n,o;y(e.credentials);let r=S(e.repo),s=`${(t=e.hubUrl)!=null?t:b}/${r.type==="model"?"":`${r.type}s/`}${r.name}/raw/${encodeURIComponent((n=e.revision)!=null?n:"main")}/${e.path}`,l=await((o=e.fetch)!=null?o:fetch)(s,{method:"HEAD",headers:e.credentials?{Authorization:`Bearer ${e.credentials.accessToken}`}:{}});if(l.status===404)return!1;if(!l.ok)throw await g(l);return!0}function G(e){let t=/<(https?:[/][/][^>]+)>;\s+rel="([^"]+)"/g;return Object.fromEntries([...e.matchAll(t)].map(([,n,o])=>[o,n]))}var Ne=["private","downloads","gated","likes","lastModified"];async function*et(e){var t,n;y(e?.credentials);let o=new URLSearchParams([...Object.entries({limit:"500",...(t=e?.search)!=null&&t.owner?{author:e.search.owner}:void 0}),...Ne.map(i=>["expand",i])]).toString(),r=`${e?.hubUrl||b}/api/datasets`+(o?"?"+o:"");for(;r;){let i=await((n=e?.fetch)!=null?n:fetch)(r,{headers:{accept:"application/json",...e?.credentials?{Authorization:`Bearer ${e.credentials.accessToken}`}:void 0}});if(!i.ok)throw g(i);let s=await i.json();for(let a of s)yield{id:a._id,name:a.id,private:a.private,downloads:a.downloads,likes:a.likes,gated:a.gated,updatedAt:new Date(a.lastModified)};let l=i.headers.get("Link");r=l?G(l).next:void 0}}async function*tt(e){var t;y(e.credentials);let n=S(e.repo),o=`${e.hubUrl||b}/api/${n.type}s/${n.name}/tree/${e.revision||"main"}${e.path?"/"+e.path:""}?recursive=${!!e.recursive}&expand=${!!e.expand}`;for(;o;){let r=await((t=e.fetch)!=null?t:fetch)(o,{headers:{accept:"application/json",...e.credentials?{Authorization:`Bearer ${e.credentials.accessToken}`}:void 0}});if(!r.ok)throw g(r);let i=await r.json();for(let l of i)yield l;let s=r.headers.get("Link");o=s?G(s).next:void 0}}var qe=["pipeline_tag","private","gated","downloads","likes"];async function*nt(e){var t,n,o;y(e?.credentials);let r=new URLSearchParams([...Object.entries({limit:"500",...(t=e?.search)!=null&&t.owner?{author:e.search.owner}:void 0,...(n=e?.search)!=null&&n.task?{pipeline_tag:e.search.task}:void 0}),...qe.map(s=>["expand",s])]).toString(),i=`${e?.hubUrl||b}/api/models?${r}`;for(;i;){let s=await((o=e?.fetch)!=null?o:fetch)(i,{headers:{accept:"application/json",...e?.credentials?{Authorization:`Bearer ${e.credentials.accessToken}`}:void 0}});if(!s.ok)throw g(s);let l=await s.json();for(let c of l)yield{id:c._id,name:c.id,private:c.private,task:c.pipeline_tag,downloads:c.downloads,gated:c.gated,likes:c.likes,updatedAt:new Date(c.lastModified)};let a=s.headers.get("Link");i=a?G(a).next:void 0}}function _e(e,t){return Object.assign({},...t.map(n=>{if(e[n]!==void 0)return{[n]:e[n]}}))}var He=["sdk","likes","private","lastModified"];async function*ot(e){var t,n,o;y(e?.credentials);let r=new URLSearchParams([...Object.entries({limit:"500",...(t=e?.search)!=null&&t.owner?{author:e.search.owner}:void 0}),...[...He,...(n=e?.additionalFields)!=null?n:[]].map(s=>["expand",s])]).toString(),i=`${e?.hubUrl||b}/api/spaces?${r}`;for(;i;){let s=await((o=e?.fetch)!=null?o:fetch)(i,{headers:{accept:"application/json",...e?.credentials?{Authorization:`Bearer ${e.credentials.accessToken}`}:void 0}});if(!s.ok)throw g(s);let l=await s.json();for(let c of l)yield{...e?.additionalFields&&_e(c,e.additionalFields),id:c._id,name:c.id,sdk:c.sdk,likes:c.likes,private:c.private,updatedAt:new Date(c.lastModified)};let a=s.headers.get("Link");i=a?G(a).next:void 0}}function ke(e,t){return e.includes(t)}function Me(e,t){let n=Array.isArray(t)?t:[t],o=Object.keys(e).filter(r=>!ke(n,r));return _e(e,o)}function $e(e){return Object.entries(e)}var fe="model.safetensors",pe="model.safetensors.index.json",Xe=5,we=25e6,x=class extends Error{};async function Te(e,t){let n=await ne({...t,path:e,range:[0,7]});if(!n)throw new x(`Failed to parse file ${e}: failed to fetch safetensors header length.`);let o=await n.arrayBuffer(),r=new DataView(o).getBigUint64(0,!0);if(r<=0)throw new x(`Failed to parse file ${e}: safetensors header is malformed.`);if(r>we)throw new x(`Failed to parse file ${e}: safetensor header is too big. Maximum supported size is ${we} bytes.`);let i=await ne({...t,path:e,range:[8,7+Number(r)]});if(!i)throw new x(`Failed to parse file ${e}: failed to fetch safetensors header.`);try{return await i.json()}catch{throw new x(`Failed to parse file ${e}: safetensors header is not valid JSON.`)}}async function Je(e,t){let n=await ne({...t,path:e});if(!n)throw new x(`Failed to parse file ${e}: failed to fetch safetensors index.`);let o=await n.json(),r=[...new Set(Object.values(o.weight_map))],i=Object.fromEntries(await be(r.map(s=>async()=>[s,await Te(s,t)]),Xe));return{index:o,headers:i}}async function rt(e){if(y(e.credentials),S(e.repo).type!=="model")throw new TypeError("Only model repos should contain safetensors files.");if(await he({...e,path:fe})){let n=await Te(fe,e);return{sharded:!1,header:n,...e.computeParametersCount&&{parameterCount:Ee(n)}}}else if(await he({...e,path:pe})){let{index:n,headers:o}=await Je(pe,e);return{sharded:!0,index:n,headers:o,...e.computeParametersCount&&{parameterCount:Ge(o)}}}else throw new Error("model id does not seem to contain safetensors weights")}function Ee(e){var t;let n={},o=Me(e,"__metadata__");for(let[,r]of $e(o))r.shape.length!==0&&(n[r.dtype]=((t=n[r.dtype])!=null?t:0)+r.shape.reduce((i,s)=>i*s));return n}function Ge(e){var t;let n={};for(let o of Object.values(e))for(let[r,i]of $e(Ee(o)))n[r]=((t=n[r])!=null?t:0)+(i??0);return n}function it(e){var t,n;let o=e.file instanceof URL?(t=e.file.pathname.split("/").at(-1))!=null?t:"file":"path"in e.file?e.file.path:e.file.name;return J({credentials:e.credentials,repo:e.repo,operations:[{operation:"addOrUpdate",path:o,content:"content"in e.file?e.file.content:e.file}],title:(n=e.commitTitle)!=null?n:`Add ${o}`,description:e.commitDescription,hubUrl:e.hubUrl,branch:e.branch,isPullRequest:e.isPullRequest,parentCommit:e.parentCommit,fetch:e.fetch,useWebWorkers:e.useWebWorkers,abortSignal:e.abortSignal})}function st(e){var t;return J({credentials:e.credentials,repo:e.repo,operations:e.files.map(n=>{var o;return{operation:"addOrUpdate",path:n instanceof URL?(o=n.pathname.split("/").at(-1))!=null?o:"file":"path"in n?n.path:n.name,content:"content"in n?n.content:n}}),title:(t=e.commitTitle)!=null?t:`Add ${e.files.length} files`,description:e.commitDescription,hubUrl:e.hubUrl,branch:e.branch,isPullRequest:e.isPullRequest,parentCommit:e.parentCommit,fetch:e.fetch,useWebWorkers:e.useWebWorkers,abortSignal:e.abortSignal})}var ge=new WeakMap;async function*at(e){var t;return yield*me({credentials:e.credentials,repo:e.repo,operations:e.files.map(n=>{var o;return{operation:"addOrUpdate",path:n instanceof URL?(o=n.pathname.split("/").at(-1))!=null?o:"file":"path"in n?n.path:n.name,content:"content"in n?n.content:n}}),title:(t=e.commitTitle)!=null?t:`Add ${e.files.length} files`,description:e.commitDescription,hubUrl:e.hubUrl,branch:e.branch,isPullRequest:e.isPullRequest,parentCommit:e.parentCommit,useWebWorkers:e.useWebWorkers,abortSignal:e.abortSignal,fetch:async(n,o)=>{var r;if(!o)return fetch(n);if(!ke(["PUT","POST"],o.method)||!("progressHint"in o)||!o.progressHint||typeof XMLHttpRequest>"u"||typeof n!="string"||!(o.body instanceof ArrayBuffer)&&!(o.body instanceof Blob)&&!(o.body instanceof File)&&typeof o.body!="string")return fetch(n,o);let i=o.progressHint,s=i.progressCallback,l=new XMLHttpRequest;return l.upload.addEventListener("progress",a=>{if(a.lengthComputable)if(i.part!==void 0){let c=ge.get(s);c||(c={numParts:i.numParts,partsProgress:{}},ge.set(s,c)),c.partsProgress[i.part]=a.loaded/a.total;let d=0;for(let u of Object.values(c.partsProgress))d+=u;d===c.numParts?s(.9999999999):s(d/c.numParts)}else a.loaded===a.total?s(.9999999999):s(a.loaded/a.total)}),l.open(o.method,n,!0),o.headers&&new Headers(o.headers).forEach((c,d)=>{l.setRequestHeader(d,c)}),(r=o.signal)==null||r.throwIfAborted(),l.send(o.body),new Promise((a,c)=>{l.addEventListener("load",()=>{a(new Response(l.responseText,{status:l.status,statusText:l.statusText,headers:Object.fromEntries(l.getAllResponseHeaders().trim().split(`
`).map(d=>[d.slice(0,d.indexOf(":")),d.slice(d.indexOf(":")+1).trim()]))}))}),l.addEventListener("error",()=>{c(new Error(l.statusText))}),o.signal&&o.signal.addEventListener("abort",()=>{var d;l.abort();try{(d=o.signal)==null||d.throwIfAborted()}catch(u){c(u)}})})}})}async function lt(e){var t,n,o;y(e.credentials);let r=await((t=e.fetch)!=null?t:fetch)(`${(n=e.hubUrl)!=null?n:b}/api/whoami-v2`,{headers:{Authorization:`Bearer ${e.credentials.accessToken}`}});if(!r.ok)throw await g(r);let i=await r.json();return typeof((o=i.auth.accessToken)==null?void 0:o.expiration)=="string"&&(i.auth.accessToken.expiration=new Date(i.auth.accessToken.expiration)),i}export{ve as HubApiError,q as InvalidApiResponseFormatError,J as commit,me as commitIter,Ke as createRepo,Ye as deleteFile,Qe as deleteFiles,Ve as deleteRepo,ne as downloadFile,Ze as fileDownloadInfo,he as fileExists,et as listDatasets,tt as listFiles,nt as listModels,ot as listSpaces,rt as parseSafetensorsMetadata,it as uploadFile,st as uploadFiles,at as uploadFilesWithProgress,lt as whoAmI};
//# sourceMappingURL=hub.mjs.map